{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irisalmeida/oficina-rag/blob/main/Agents4good_oficina_rag.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMxvmZ7-Za4_"
      },
      "source": [
        "# **Leitor Inteligente de PDFs com Imagens**\n",
        "\n",
        "Aplicação que responde perguntas sobre PDFs usando IA multimodal e busca semântica com geração aumentada por recuperação (RAG)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6OeYfGN88O-"
      },
      "source": [
        "#### **Configuração do Ambiente**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OijIIhFR9Zss"
      },
      "source": [
        "##### **Instalação de Pacotes Necessários**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dN7qy-nUZUuk"
      },
      "outputs": [],
      "source": [
        "!pip install -U -q langgraph langchain langchain-google-genai langchain_community faiss-cpu pdf2image PyMuPDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Fy04_20aZqI"
      },
      "source": [
        "##### **Definição da chave da API do Google AI**\n",
        "Gerar uma API Key no [Google AI Studio](https://aistudio.google.com/prompts/new_chat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JToYtlPiZb-R"
      },
      "outputs": [],
      "source": [
        "import os, getpass\n",
        "\n",
        "#Adicione sua chave abaixo:\n",
        "#os.environ[\"GOOGLE_API_KEY\"] = \"sua-chave-aqui\"\n",
        "\n",
        "if not os.getenv(\"GOOGLE_API_KEY\"):\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google API key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Upload do PDF**"
      ],
      "metadata": {
        "id": "P2SFI5F8idXO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcMuP7tVSYzd"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"pdf_images\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "pdf_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "aEb0shFh5xM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Inicialização do LLM**"
      ],
      "metadata": {
        "id": "ZqJwpRXbl1Le"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMmEAxcXTohV"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Extraindo Texto e Imagens do PDF**"
      ],
      "metadata": {
        "id": "DF_HXrSTlu19"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCogtK9jSw94"
      },
      "outputs": [],
      "source": [
        "from pdf2image import convert_from_path\n",
        "import fitz\n",
        "import base64\n",
        "from langchain_core.documents import Document\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "text_chunks = []\n",
        "image_descriptions = []\n",
        "doc = fitz.open(pdf_path)\n",
        "\n",
        "for i, page in enumerate(doc):\n",
        "    text = page.get_text(\"text\")\n",
        "    if text:\n",
        "        text_chunks.append(Document(page_content=text.strip(), metadata={\"page\": i}))\n",
        "\n",
        "    image_list = page.get_images(full=True)\n",
        "    for j, img in enumerate(image_list):\n",
        "        xref = img[0]\n",
        "        base_image = doc.extract_image(xref)\n",
        "        image_bytes = base_image[\"image\"]\n",
        "        image_path = f\"pdf_images/page_{i}_img_{j}.png\"\n",
        "        with open(image_path, \"wb\") as f:\n",
        "            f.write(image_bytes)\n",
        "\n",
        "        image_b64 = base64.b64encode(image_bytes).decode()\n",
        "        vision_response = llm.invoke([\n",
        "            HumanMessage(\n",
        "                content=[\n",
        "                    {\"type\": \"text\", \"text\": \"Descreva com detalhes o conteúdo da imagem.\"},\n",
        "                    {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{image_b64}\"}}\n",
        "                ]\n",
        "            )\n",
        "        ])\n",
        "        image_desc = vision_response.content.strip()\n",
        "        image_descriptions.append(Document(\n",
        "            page_content=image_desc,\n",
        "            metadata={\n",
        "                \"image_path\": image_path,\n",
        "                \"image_base64\": image_b64,\n",
        "                \"page\": i,\n",
        "                \"image_index\": j\n",
        "            }\n",
        "        ))\n",
        "\n",
        "all_documents = text_chunks + image_descriptions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Gerando embeddings e indexando conteúdo**\n",
        "\n",
        "Modelo de embedding: [sentence-transformers/all-MiniLM-L6-v2](https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2)"
      ],
      "metadata": {
        "id": "y8YeSS0wjXT8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3vDu5ryaSxB-"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "vectorstore = FAISS.from_documents(all_documents, embedding=embeddings)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Construção do Grafo**"
      ],
      "metadata": {
        "id": "9QQtTmsDmXtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import hub\n",
        "from langgraph.graph import START, END, StateGraph\n",
        "from typing_extensions import TypedDict, List\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "\n",
        "class State(TypedDict):\n",
        "    question: str\n",
        "    context: List[Document]\n",
        "    answer: str\n",
        "\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")\n",
        "\n",
        "def retrieve(state: State):\n",
        "    docs = vectorstore.similarity_search(state[\"question\"], k=7)\n",
        "    return {\"context\": docs}\n",
        "\n",
        "def generate(state: State):\n",
        "    context_parts = []\n",
        "    for doc in state[\"context\"]:\n",
        "        text = doc.page_content\n",
        "        img_b64 = doc.metadata.get(\"image_base64\")\n",
        "        if img_b64:\n",
        "            image_tag = f\"\\n[Imagem relacionada: data:image/png;base64,{img_b64}]\\n\"\n",
        "            context_parts.append(text + image_tag)\n",
        "        else:\n",
        "            context_parts.append(text)\n",
        "\n",
        "    context_text = \"\\n\\n\".join(context_parts)\n",
        "\n",
        "    messages = prompt.invoke({\n",
        "        \"question\": state[\"question\"],\n",
        "        \"context\": context_text\n",
        "    })\n",
        "    result = llm.invoke(messages)\n",
        "    return {\"answer\": result.content}\n",
        "\n",
        "graph_builder = StateGraph(State)\n",
        "graph_builder.add_node(\"retrieve\", retrieve)\n",
        "graph_builder.add_node(\"generate\", generate)\n",
        "graph_builder.add_edge(START, \"retrieve\")\n",
        "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
        "graph_builder.add_edge(\"generate\", END)\n",
        "graph = graph_builder.compile()\n"
      ],
      "metadata": {
        "id": "RypbQupv66NT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Visualização do Grafo**"
      ],
      "metadata": {
        "id": "VJpv8Pzumcj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image, display\n",
        "try:\n",
        "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
        "except Exception:\n",
        "    pass"
      ],
      "metadata": {
        "id": "ZEcf1pCIOnDm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question = input(\"Digite sua pergunta sobre o PDF: \")\n",
        "result = graph.invoke({\"question\": question})\n",
        "\n",
        "print(\"\\n Resposta:\\n\")\n",
        "print(result[\"answer\"])\n",
        "\n",
        "print(\"\\n Imagens relevantes: \\n\")\n",
        "for doc in result[\"context\"]:\n",
        "    if \"image_path\" in doc.metadata:\n",
        "        display(Image(doc.metadata[\"image_path\"]))"
      ],
      "metadata": {
        "id": "VNZg46DK66RD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}